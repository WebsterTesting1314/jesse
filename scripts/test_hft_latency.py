#!/usr/bin/env python3
"""
HFT å»¶é²æ¸¬è©¦è…³æœ¬
æ¸¬è©¦é«˜é »äº¤æ˜“çµ„ä»¶çš„å»¶é²æ€§èƒ½
"""

import sys
import time
import numpy as np
import statistics
from pathlib import Path

# æ·»åŠ æ ¸å¿ƒæ¨¡çµ„è·¯å¾‘
sys.path.insert(0, str(Path(__file__).parent.parent / "core"))

try:
    from jesse.indicators.hft_optimized import hft_sma, hft_ema, hft_rsi
    from jesse.services.hft_cache import hft_cache_manager
    from jesse.services.hft_event_system import hft_event_bus
    from jesse.store.hft_optimized_orders import hft_order_manager
except ImportError as e:
    print(f"âš ï¸ Warning: HFT modules not available: {e}")
    print("Some tests will be skipped.")

class HFTLatencyTester:
    """HFT å»¶é²æ¸¬è©¦å™¨"""
    
    def __init__(self):
        self.results = {}
        self.max_latency_us = 100  # 100 å¾®ç§’é–¾å€¼
        
    def test_indicator_latency(self) -> dict:
        """æ¸¬è©¦æŒ‡æ¨™è¨ˆç®—å»¶é²"""
        print("ğŸ” Testing HFT Indicator Latency...")
        
        # æº–å‚™æ¸¬è©¦æ•¸æ“š
        prices = np.random.random(1000).astype(np.float64) * 50000
        iterations = 1000
        
        results = {}
        
        try:
            # æ¸¬è©¦ SMA å»¶é²
            latencies = []
            for _ in range(iterations):
                start = time.perf_counter()
                hft_sma(prices, 20)
                end = time.perf_counter()
                latencies.append((end - start) * 1_000_000)  # è½‰æ›ç‚ºå¾®ç§’
            
            results['sma'] = {
                'mean_us': statistics.mean(latencies),
                'median_us': statistics.median(latencies),
                'p95_us': np.percentile(latencies, 95),
                'max_us': max(latencies)
            }
            
            # æ¸¬è©¦ EMA å»¶é²
            latencies = []
            for _ in range(iterations):
                start = time.perf_counter()
                hft_ema(prices, 20)
                end = time.perf_counter()
                latencies.append((end - start) * 1_000_000)
            
            results['ema'] = {
                'mean_us': statistics.mean(latencies),
                'median_us': statistics.median(latencies),
                'p95_us': np.percentile(latencies, 95),
                'max_us': max(latencies)
            }
            
            # æ¸¬è©¦ RSI å»¶é²
            latencies = []
            for _ in range(iterations):
                start = time.perf_counter()
                hft_rsi(prices, 14)
                end = time.perf_counter()
                latencies.append((end - start) * 1_000_000)
            
            results['rsi'] = {
                'mean_us': statistics.mean(latencies),
                'median_us': statistics.median(latencies),
                'p95_us': np.percentile(latencies, 95),
                'max_us': max(latencies)
            }
            
        except Exception as e:
            print(f"âŒ Indicator latency test failed: {e}")
            return {'error': str(e)}
        
        return results
    
    def test_cache_latency(self) -> dict:
        """æ¸¬è©¦ç·©å­˜å»¶é²"""
        print("ğŸ” Testing Cache Latency...")
        
        try:
            # åˆå§‹åŒ–ç·©å­˜ç®¡ç†å™¨
            cache_manager = hft_cache_manager
            
            # æ¸¬è©¦å¯«å…¥å»¶é²
            write_latencies = []
            for i in range(1000):
                start = time.perf_counter()
                cache_manager.set_position_cache(f"test_key_{i}", {"price": 50000 + i})
                end = time.perf_counter()
                write_latencies.append((end - start) * 1_000_000)
            
            # æ¸¬è©¦è®€å–å»¶é²
            read_latencies = []
            for i in range(1000):
                start = time.perf_counter()
                cache_manager.get_position_cache(f"test_key_{i}")
                end = time.perf_counter()
                read_latencies.append((end - start) * 1_000_000)
            
            return {
                'write': {
                    'mean_us': statistics.mean(write_latencies),
                    'p95_us': np.percentile(write_latencies, 95),
                    'max_us': max(write_latencies)
                },
                'read': {
                    'mean_us': statistics.mean(read_latencies),
                    'p95_us': np.percentile(read_latencies, 95),
                    'max_us': max(read_latencies)
                }
            }
            
        except Exception as e:
            print(f"âŒ Cache latency test failed: {e}")
            return {'error': str(e)}
    
    def test_order_management_latency(self) -> dict:
        """æ¸¬è©¦è¨‚å–®ç®¡ç†å»¶é²"""
        print("ğŸ” Testing Order Management Latency...")
        
        try:
            # æ¸¬è©¦è¨‚å–®æ·»åŠ å»¶é²
            add_latencies = []
            for i in range(1000):
                order_data = {
                    'id': f'order_{i}',
                    'symbol': 'BTCUSDT',
                    'side': 'buy',
                    'quantity': 0.001,
                    'price': 50000 + i
                }
                
                start = time.perf_counter()
                # é€™è£¡æ‡‰è©²èª¿ç”¨å¯¦éš›çš„è¨‚å–®ç®¡ç†å™¨
                # hft_order_manager.add_order(order_data)
                end = time.perf_counter()
                add_latencies.append((end - start) * 1_000_000)
            
            # æ¸¬è©¦è¨‚å–®æŸ¥æ‰¾å»¶é²
            lookup_latencies = []
            for i in range(1000):
                start = time.perf_counter()
                # é€™è£¡æ‡‰è©²èª¿ç”¨å¯¦éš›çš„è¨‚å–®æŸ¥æ‰¾
                # hft_order_manager.get_order(f'order_{i}')
                end = time.perf_counter()
                lookup_latencies.append((end - start) * 1_000_000)
            
            return {
                'add': {
                    'mean_us': statistics.mean(add_latencies),
                    'p95_us': np.percentile(add_latencies, 95),
                    'max_us': max(add_latencies)
                },
                'lookup': {
                    'mean_us': statistics.mean(lookup_latencies),
                    'p95_us': np.percentile(lookup_latencies, 95),
                    'max_us': max(lookup_latencies)
                }
            }
            
        except Exception as e:
            print(f"âŒ Order management latency test failed: {e}")
            return {'error': str(e)}
    
    def validate_results(self, results: dict) -> bool:
        """é©—è­‰çµæœæ˜¯å¦ç¬¦åˆæ€§èƒ½è¦æ±‚"""
        print("\nğŸ“Š Validating Performance Requirements...")
        
        passed = True
        
        # é©—è­‰æŒ‡æ¨™å»¶é²
        if 'indicators' in results:
            for indicator, metrics in results['indicators'].items():
                if 'error' not in metrics:
                    p95_latency = metrics.get('p95_us', float('inf'))
                    if p95_latency > self.max_latency_us:
                        print(f"âŒ {indicator.upper()} P95 latency {p95_latency:.2f}Î¼s > {self.max_latency_us}Î¼s")
                        passed = False
                    else:
                        print(f"âœ… {indicator.upper()} P95 latency {p95_latency:.2f}Î¼s â‰¤ {self.max_latency_us}Î¼s")
        
        # é©—è­‰ç·©å­˜å»¶é²
        if 'cache' in results and 'error' not in results['cache']:
            read_p95 = results['cache']['read'].get('p95_us', float('inf'))
            write_p95 = results['cache']['write'].get('p95_us', float('inf'))
            
            if read_p95 > self.max_latency_us:
                print(f"âŒ Cache read P95 latency {read_p95:.2f}Î¼s > {self.max_latency_us}Î¼s")
                passed = False
            else:
                print(f"âœ… Cache read P95 latency {read_p95:.2f}Î¼s â‰¤ {self.max_latency_us}Î¼s")
                
            if write_p95 > self.max_latency_us:
                print(f"âŒ Cache write P95 latency {write_p95:.2f}Î¼s > {self.max_latency_us}Î¼s")
                passed = False
            else:
                print(f"âœ… Cache write P95 latency {write_p95:.2f}Î¼s â‰¤ {self.max_latency_us}Î¼s")
        
        return passed
    
    def run_all_tests(self) -> bool:
        """é‹è¡Œæ‰€æœ‰å»¶é²æ¸¬è©¦"""
        print("ğŸš€ Starting HFT Latency Tests...")
        print(f"ğŸ¯ Target: All operations < {self.max_latency_us}Î¼s (P95)")
        
        # é‹è¡ŒæŒ‡æ¨™æ¸¬è©¦
        self.results['indicators'] = self.test_indicator_latency()
        
        # é‹è¡Œç·©å­˜æ¸¬è©¦
        self.results['cache'] = self.test_cache_latency()
        
        # é‹è¡Œè¨‚å–®ç®¡ç†æ¸¬è©¦
        self.results['order_management'] = self.test_order_management_latency()
        
        # æ‰“å°è©³ç´°çµæœ
        self.print_detailed_results()
        
        # é©—è­‰çµæœ
        passed = self.validate_results(self.results)
        
        if passed:
            print("\nâœ… All HFT latency tests passed!")
            return True
        else:
            print("\nâŒ Some HFT latency tests failed!")
            return False
    
    def print_detailed_results(self):
        """æ‰“å°è©³ç´°æ¸¬è©¦çµæœ"""
        print("\nğŸ“Š Detailed Latency Test Results:")
        print("=" * 60)
        
        for category, results in self.results.items():
            print(f"\nğŸ“ˆ {category.upper()} Results:")
            if 'error' in results:
                print(f"   âŒ Error: {results['error']}")
                continue
                
            if category == 'indicators':
                for indicator, metrics in results.items():
                    print(f"   {indicator.upper()}:")
                    print(f"     Mean: {metrics['mean_us']:.2f}Î¼s")
                    print(f"     P95:  {metrics['p95_us']:.2f}Î¼s")
                    print(f"     Max:  {metrics['max_us']:.2f}Î¼s")
            elif category in ['cache', 'order_management']:
                for operation, metrics in results.items():
                    print(f"   {operation.upper()}:")
                    print(f"     Mean: {metrics['mean_us']:.2f}Î¼s")
                    print(f"     P95:  {metrics['p95_us']:.2f}Î¼s")
                    print(f"     Max:  {metrics['max_us']:.2f}Î¼s")

def main():
    """ä¸»å‡½æ•¸"""
    tester = HFTLatencyTester()
    
    try:
        success = tester.run_all_tests()
        sys.exit(0 if success else 1)
    except Exception as e:
        print(f"âŒ Test execution failed: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main() 